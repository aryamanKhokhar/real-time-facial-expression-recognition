{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODvM3IhHPnfi"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jiyf-GaAczh"
   },
   "outputs": [],
   "source": [
    "# TensorFlow and Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "# General libraries for data handling and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQvrOpTNP4VE"
   },
   "source": [
    "# Uploading Files and Setting Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "16IS9x7xCq6s",
    "outputId": "9683526a-4c6b-4d34-a1d0-278e1ce7e3bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b9297854-2980-45c9-a06f-7d7df7b1f0b6\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b9297854-2980-45c9-a06f-7d7df7b1f0b6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset.zip to dataset.zip\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHNIZ6nsE_BI"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('dataset')  # Extract to a 'dataset' folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LwDQ_c_F3Xa",
    "outputId": "8faa2cf3-4f3b-45b0-a963-8cdcafd86ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disgust', 'fear', 'angry', 'neutral', 'sad', 'happy', 'surprise']\n",
      "['disgust', 'fear', 'angry', 'neutral', 'sad', 'happy', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verify the directory structure\n",
    "print(os.listdir('dataset/images/train'))  # Should list emotion folders in train\n",
    "print(os.listdir('dataset/images/validation'))   # Should list emotion folders in test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDwDTi2FGBr7"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'dataset/images/train'\n",
    "TEST_DIR = 'dataset/images/validation'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZfRO-6-QTDU"
   },
   "source": [
    "# Preparing Dataset: Image Paths and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur6bMZ-SG1_Q"
   },
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []  # List to store the paths of all images\n",
    "    labels = []       # List to store the corresponding labels for each image\n",
    "\n",
    "    # Loop over all the directories (labels) in the given directory\n",
    "    for label in os.listdir(dir):\n",
    "        # Loop over all images in each label folder\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            # Construct the full path of the image\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            # Append the label (emotion) corresponding to this image\n",
    "            labels.append(label)\n",
    "\n",
    "        print(label, \"completed\")  # Indicating the label (emotion) folder has been processed\n",
    "\n",
    "    return image_paths, labels  # Return the lists of image paths and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQGVF7tsIA4q",
    "outputId": "7248ef35-fb7d-413b-9ed3-27572b3f4e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disgust completed\n",
      "fear completed\n",
      "angry completed\n",
      "neutral completed\n",
      "sad completed\n",
      "happy completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wG3iu3_-IIn7",
    "outputId": "ab3ed2c7-6a19-42e7-f63c-937352a74f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         image     label\n",
      "0       dataset/images/train/disgust/19257.jpg   disgust\n",
      "1        dataset/images/train/disgust/1073.jpg   disgust\n",
      "2       dataset/images/train/disgust/10236.jpg   disgust\n",
      "3        dataset/images/train/disgust/5335.jpg   disgust\n",
      "4        dataset/images/train/disgust/4889.jpg   disgust\n",
      "...                                        ...       ...\n",
      "28816    dataset/images/train/surprise/332.jpg  surprise\n",
      "28817  dataset/images/train/surprise/29747.jpg  surprise\n",
      "28818  dataset/images/train/surprise/35540.jpg  surprise\n",
      "28819  dataset/images/train/surprise/21995.jpg  surprise\n",
      "28820  dataset/images/train/surprise/23899.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuM1N9nqIQVQ",
    "outputId": "7736660a-4397-482d-a615-ce49b8ad04fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disgust completed\n",
      "fear completed\n",
      "angry completed\n",
      "neutral completed\n",
      "sad completed\n",
      "happy completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Dyo3o7_Ix3s",
    "outputId": "ab60a5c0-434c-4e98-f41a-0bedc84bb5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             image     label\n",
      "0      dataset/images/validation/disgust/28332.jpg   disgust\n",
      "1       dataset/images/validation/disgust/9043.jpg   disgust\n",
      "2      dataset/images/validation/disgust/31796.jpg   disgust\n",
      "3       dataset/images/validation/disgust/7068.jpg   disgust\n",
      "4      dataset/images/validation/disgust/35376.jpg   disgust\n",
      "...                                            ...       ...\n",
      "7061  dataset/images/validation/surprise/11126.jpg  surprise\n",
      "7062  dataset/images/validation/surprise/31781.jpg  surprise\n",
      "7063   dataset/images/validation/surprise/6360.jpg  surprise\n",
      "7064  dataset/images/validation/surprise/23053.jpg  surprise\n",
      "7065   dataset/images/validation/surprise/5636.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9wtYgR6Qt4y"
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MckUh1zqJ4pn"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        # Use color_mode='grayscale' instead of grayscale=True\n",
    "        img = load_img(image, color_mode='grayscale', target_size=(48, 48))\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2a8414de31284be5a390a6a3ac93153f",
      "c07ede2931d34fa8ae1a83497b3e1567",
      "4a011e2fe53a45dbabb1ea01ae39df84",
      "4b26df25542945c7afb19a26946e1897",
      "61ddf49c42864a80aeb8f46c21d036b9",
      "68544d11c9f94fcea817d3d9072ae437",
      "22e2ed9702294133b378c3cfb0ab5eb6",
      "aecae9c8f626493da4038cf2a37bbb2a",
      "f97c917e6466487fb692a3266947f624",
      "d8bd15ca8ac248cf897cf790ef3474ba",
      "bb356a38b1a747378022f88f90c01644"
     ]
    },
    "id": "nb0CYW6cK8ZN",
    "outputId": "3d0d00c2-d2ad-4ba1-c6aa-4ed5c50bd792"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8414de31284be5a390a6a3ac93153f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "737aac2f41064aab936916b4303e665d",
      "1a77d8a5bb594484a8d6b5b094d1b30d",
      "04acc9d98249491ea102cf75ff34c6a5",
      "c0d5a73952b64cabb484ea3d71fac497",
      "5e3a2eaa4f5740e293b96b0132a5bb00",
      "2dc2d78067654eca94c58b934b22a872",
      "f23c46549b4b4a01b393fd7e7c1c41f2",
      "a430907480cf4ae697cbf4665dcd9be3",
      "ce9c77f2e85c4eafad4fb1953da33b7e",
      "e3603c35705d4e07a408313368488c10",
      "1a3372a4eae6408dbf473089c9ccc85f"
     ]
    },
    "id": "VHW4IvR9LkUf",
    "outputId": "1af6ef2a-d42a-47f9-993f-7b5e7d40405f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737aac2f41064aab936916b4303e665d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "687nOrDlRHrq"
   },
   "source": [
    "# Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J85qlfikLwZM"
   },
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xPzjG1JRV6a"
   },
   "source": [
    "# One Hot Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cadyMzUiL7iZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder instance\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the training labels\n",
    "le.fit(train['label'])\n",
    "\n",
    "# Transform the labels into numerical values\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG9pqfBiM5Qb"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes = 7)\n",
    "y_test = to_categorical(y_test,num_classes = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAlGmWrGRkrc"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSSQTwGZQXIH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNonIyRJRo_g"
   },
   "source": [
    "# Building and Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKSIg6PjNuK6"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "model = Sequential()\n",
    "# Convolutional layers with batch normalization\n",
    "model.add(Conv2D(128, kernel_size=(3,3), input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())  # Apply batch normalization\n",
    "model.add(Activation('relu'))  # Apply activation after normalization\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers with batch normalization\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HI1f9aoNOJrd"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKepNeN3Ryp9"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5_r2vA7TlS2",
    "outputId": "35b5f6bb-cfff-429f-cb4b-da0b853f1cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.6395 - loss: 0.9454 - val_accuracy: 0.5633 - val_loss: 1.1858\n",
      "Epoch 2/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.6498 - loss: 0.9146 - val_accuracy: 0.5894 - val_loss: 1.1082\n",
      "Epoch 3/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.6551 - loss: 0.9226 - val_accuracy: 0.5863 - val_loss: 1.1114\n",
      "Epoch 4/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.6704 - loss: 0.8754 - val_accuracy: 0.5761 - val_loss: 1.1363\n",
      "Epoch 5/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.6846 - loss: 0.8555 - val_accuracy: 0.5638 - val_loss: 1.1767\n",
      "Epoch 6/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.6876 - loss: 0.8387 - val_accuracy: 0.6044 - val_loss: 1.1104\n",
      "Epoch 7/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.7005 - loss: 0.8132 - val_accuracy: 0.5918 - val_loss: 1.1248\n",
      "Epoch 8/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.6988 - loss: 0.7934 - val_accuracy: 0.5740 - val_loss: 1.2579\n",
      "Epoch 9/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.7064 - loss: 0.7814 - val_accuracy: 0.5570 - val_loss: 1.2196\n",
      "Epoch 10/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.7221 - loss: 0.7455 - val_accuracy: 0.6102 - val_loss: 1.0810\n",
      "Epoch 11/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.7267 - loss: 0.7341 - val_accuracy: 0.5086 - val_loss: 1.4585\n",
      "Epoch 12/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7336 - loss: 0.7133 - val_accuracy: 0.5904 - val_loss: 1.1766\n",
      "Epoch 13/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.7443 - loss: 0.6895 - val_accuracy: 0.6077 - val_loss: 1.1372\n",
      "Epoch 14/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6686 - val_accuracy: 0.6381 - val_loss: 1.0609\n",
      "Epoch 15/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.7554 - loss: 0.6506 - val_accuracy: 0.5474 - val_loss: 1.4046\n",
      "Epoch 16/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.7649 - loss: 0.6380 - val_accuracy: 0.6001 - val_loss: 1.2239\n",
      "Epoch 17/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.7699 - loss: 0.6190 - val_accuracy: 0.6398 - val_loss: 1.0586\n",
      "Epoch 18/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7789 - loss: 0.5999 - val_accuracy: 0.4890 - val_loss: 1.6840\n",
      "Epoch 19/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.7917 - loss: 0.5713 - val_accuracy: 0.5081 - val_loss: 1.5975\n",
      "Epoch 20/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.7932 - loss: 0.5663 - val_accuracy: 0.6230 - val_loss: 1.1598\n",
      "Epoch 21/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.7971 - loss: 0.5567 - val_accuracy: 0.5947 - val_loss: 1.3214\n",
      "Epoch 22/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.7983 - loss: 0.5406 - val_accuracy: 0.6029 - val_loss: 1.2292\n",
      "Epoch 23/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.8078 - loss: 0.5236 - val_accuracy: 0.5872 - val_loss: 1.2578\n",
      "Epoch 24/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.8127 - loss: 0.5104 - val_accuracy: 0.6033 - val_loss: 1.2695\n",
      "Epoch 25/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.8189 - loss: 0.4932 - val_accuracy: 0.5117 - val_loss: 1.7803\n",
      "Epoch 26/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.8236 - loss: 0.4814 - val_accuracy: 0.6183 - val_loss: 1.2397\n",
      "Epoch 27/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.8283 - loss: 0.4704 - val_accuracy: 0.5735 - val_loss: 1.4044\n",
      "Epoch 28/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.8277 - loss: 0.4732 - val_accuracy: 0.6194 - val_loss: 1.2919\n",
      "Epoch 29/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.8385 - loss: 0.4521 - val_accuracy: 0.5920 - val_loss: 1.4164\n",
      "Epoch 30/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.8440 - loss: 0.4354 - val_accuracy: 0.6202 - val_loss: 1.3046\n",
      "Epoch 31/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.8464 - loss: 0.4243 - val_accuracy: 0.6286 - val_loss: 1.2714\n",
      "Epoch 32/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.8461 - loss: 0.4214 - val_accuracy: 0.5500 - val_loss: 1.6598\n",
      "Epoch 33/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.8503 - loss: 0.4100 - val_accuracy: 0.5801 - val_loss: 1.4417\n",
      "Epoch 34/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.8577 - loss: 0.3966 - val_accuracy: 0.5989 - val_loss: 1.3985\n",
      "Epoch 35/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.8592 - loss: 0.3882 - val_accuracy: 0.6485 - val_loss: 1.2782\n",
      "Epoch 36/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.8562 - loss: 0.3939 - val_accuracy: 0.6281 - val_loss: 1.2978\n",
      "Epoch 37/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.8690 - loss: 0.3706 - val_accuracy: 0.5940 - val_loss: 1.5306\n",
      "Epoch 38/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.8635 - loss: 0.3730 - val_accuracy: 0.6264 - val_loss: 1.3468\n",
      "Epoch 39/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.8667 - loss: 0.3694 - val_accuracy: 0.5825 - val_loss: 1.4920\n",
      "Epoch 40/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.8771 - loss: 0.3462 - val_accuracy: 0.6135 - val_loss: 1.3670\n",
      "Epoch 41/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.8758 - loss: 0.3484 - val_accuracy: 0.6261 - val_loss: 1.3508\n",
      "Epoch 42/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.8823 - loss: 0.3322 - val_accuracy: 0.6292 - val_loss: 1.3799\n",
      "Epoch 43/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.8765 - loss: 0.3412 - val_accuracy: 0.6286 - val_loss: 1.4141\n",
      "Epoch 44/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.8790 - loss: 0.3370 - val_accuracy: 0.6241 - val_loss: 1.3986\n",
      "Epoch 45/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.8827 - loss: 0.3281 - val_accuracy: 0.6258 - val_loss: 1.4176\n",
      "Epoch 46/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.8867 - loss: 0.3187 - val_accuracy: 0.6214 - val_loss: 1.4889\n",
      "Epoch 47/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.8878 - loss: 0.3170 - val_accuracy: 0.5685 - val_loss: 1.6598\n",
      "Epoch 48/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.8885 - loss: 0.3099 - val_accuracy: 0.5723 - val_loss: 1.6133\n",
      "Epoch 49/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.8881 - loss: 0.3088 - val_accuracy: 0.6151 - val_loss: 1.4886\n",
      "Epoch 50/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 60ms/step - accuracy: 0.8893 - loss: 0.3099 - val_accuracy: 0.5123 - val_loss: 1.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7efd0158f690>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 50, validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHt1-9Oda1hP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Save the full model (architecture + weights)\n",
    "model.save(\"emotion_model.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB_a4YUxR9GI"
   },
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "u9OLx3BecrW7",
    "outputId": "780fd516-5154-420d-c549-73b9fbc8516d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928ms/step\n",
      "Model prediction: sad\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Your label names\n",
    "labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, color_mode='grayscale', target_size=(48, 48))\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape(1, 48, 48, 1)  # Add batch & channel dims\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# Path to your test image (update this! after uploading)\n",
    "image_path = '42.jpg'  # Use the name of the uploaded image\n",
    "img = preprocess_image(image_path)\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(img)\n",
    "pred_label = labels[pred.argmax()]\n",
    "print(\"Model prediction:\", pred_label)\n",
    "\n",
    "# Display the image with the predicted label\n",
    "img = load_img(image_path, color_mode='grayscale', target_size=(48, 48))  # Re-load image for display\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Predicted: {pred_label}\")\n",
    "plt.axis('off')  # Turn off axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "AbYhj6zVltV6",
    "outputId": "a6e723e3-3b9b-4fb3-9f69-e9964aa5feed"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_3a34b390-3da1-43f4-b5b5-9d94b58a70ed\", \"emotion_model.keras\", 50974393)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/emotion_model.keras')  # Download to your computer\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ODvM3IhHPnfi",
    "y9wtYgR6Qt4y",
    "687nOrDlRHrq",
    "0xPzjG1JRV6a",
    "eAlGmWrGRkrc",
    "zB_a4YUxR9GI"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
